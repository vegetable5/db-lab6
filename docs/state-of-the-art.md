# Аналіз предметної області

## Вступ

***У цьому документі містяться основні відомості аналізу сфери управління відкритими даними. Документ включає:***
 - [Основні визначення](#основні-визначення)
 - [Підходи та способи вирішення завдання](#підходи-та-способи-вирішення-завдання)
 - [Порівняльна характеристика існуючих засобів вирішення завдання](#підходи-та-способи-вирішення-завдання)
 - [Висновки](#висновки)
 - [Посилання](#посилання)


## Основні визначення

**Дані (data)** - відомості, отримані шляхом вимірювання, спостереження, логічних або арифметичних операцій і представлені у формі, придатній для постійного зберігання, передачі і (автоматизованої) обробки.

**SQL (Structured Query Language)** — декларативна мова програмування для взаємодії користувача з базами даних, що застосовується для формування запитів, оновлення і керування реляційними БД, створення схеми бази даних та її модифікації, системи контролю за доступом до бази даних. Сама по собі SQL не є ані системою керування базами даних, ані окремим програмним продуктом. На відміну від дійсних мов програмування (C або Pascal), SQL може формувати інтерактивні запити або, бувши вбудованою в прикладні програми, виступати як інструкції для керування даними. Окрім цього, стандарт SQL містить функції для визначення зміни, перевірки та захисту даних.

**[База даних (англ. Database)](https://apeps.kpi.ua/shco-take-basa-danykh)** - це організована структура, яка призначена для зберігання, зміни та обробки взаємозалежної інформації, переважно великих обсягів.

**[СУБД (Система управління базами даних](https://apeps.kpi.ua/shco-take-basa-danykh)** — це програмні засоби, які виступають посередником між БД та її користувачами. Завдяки сукупності мовних та програмних засобів, СУБД сприяють створенню, ведення та спільного використання БД різними користувачами.

**[РБД (Розподілені бази даних)](https://apeps.kpi.ua/shco-take-basa-danykh)** — це сукупність логічно пов'язаних між собою БД, які є розподіленими у комп'ютерній мережі.

**[Відкриті дані (англ. Open data)](https://leadscanner.com.ua/articles/open-data)** - концепція, яка відображає ідею про те, що певні дані повинні бути вільно доступні для машиночитаемого використання і подальшої передруку без обмежень авторського права, патентів та інших механізмів контролю. Звільнити дані від обмежень авторського права можна за допомогою вільних ліцензій, таких як ліцензій Creative Commons. Якщо який-небудь набір даних не є суспільним надбанням, або не пов'язаний ліцензією, що дає права на вільне повторне використання, то такий набір даних не вважається відкритим, навіть якщо він викладений в машиночитаемом вигляді в Інтернет.

**[Ролева модель доступу (англ. Role-Based Access Control, RBAC)](https://uk.wikipedia.org/wiki/%D0%9A%D0%B5%D1%80%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F_%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%BE%D0%BC_%D0%BD%D0%B0_%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D1%96_%D1%80%D0%BE%D0%BB%D0%B5%D0%B9)** — розвиток політики вибіркового керування доступом, при якому права доступу суб'єктів системи на об'єкти групуються з урахуванням специфіки їх застосування, утворюючи ролі.

**[Прикладний програмний інтерфейс (англ. Application Programming Interface, API)](https://ua.nesrakonk.ru/application-programming-interface/)** - це набір програмного коду, який запитує дані, аналізує відповіді та надсилає інструкції між однією програмною платформою. API широко використовуються для надання послуг передачі даних у різних сферах та контекстах.

**[Реляційна база даних (англ. Relation Data Base Management System, RDBMS)](https://ua5.org/database/189-reljacjjna-baza-danikh.html)** - це структурована колекція даних, яка організована у вигляді таблиць. Кожна таблиця складається з рядків і стовпців, де рядки представляють конкретні записи, а стовпці визначають типи даних, які можуть бути збережені. Реляційна база даних використовує спеціальні зв’язки між таблицями, щоб увізуалізувати і зберігати залежності між даними.

**[Нереляційна база даних (англ. Non Relation Data Base)](https://www.google.com/search?q=non+relational+database&oq=no+relation&aqs=chrome.1.69i57j0i10i512j0i512l2j0i10i512l2j0i512l3j0i10i512.5519j0j4&sourceid=chrome&ie=UTF-8)** - база даних, яка зберігає дані без чітких зв’язків між собою та без чіткої структури. Замість структурованих таблиць, всередині бази знаходиться безліч різнорідних документів, в тому числі і зображення, відео та навіть публікації у соціальних мережах. На відміну від реляційних БД, NoSQL бази не підтримують SQL запити. 

## Підходи та способи вирішення завдання


Системи управління відкритими даними створюють умови для ефективного використання даних, підвищення прозорості організаційної діяльності та сприяння інноваціям. Однак, щоб досягти цих цілей, необхідно впроваджувати різноманітні підходи та методи, що забезпечують належне управління даними на всіх етапах їхнього життєвого циклу.

**Життєвий цикл даних (data lifecycle)** — це процес, що охоплює всі етапи від створення даних до їх знищення або архівування. Цей цикл включає різні стадії, на кожній з яких дані проходять певні операції, що впливають на їх якість, доступність та безпеку. Основні етапи життєвого циклу даних:

1. Створення даних

2. Обробка даних

3. Зберігання даних

4. Аналіз даних

5. Безпека даних

6. Поширення даних

7. Архівування та знищення даних

### Створення даних
Це перший етап, який включає збір, генерування або отримання даних. Дані можуть створюватися через різні методи, такі як опитування, автоматизоване збирання з сенсорів, імпорт з інших систем або формування нових даних шляхом обробки існуючих. Важливо, щоб дані були зібрані у відповідності до визначених стандартів та вимог, щоб забезпечити їхню якість та точність.

#### 1. Опитування та анкетування
Опитування є одним із найпоширеніших способів збору даних. Це дозволяє отримувати інформацію безпосередньо від респондентів

- Google Forms: 
  - Безкоштовний інструмент для створення форм і опитувань
  - Легко інтегрується з Google Sheets для аналізу даних
  
- SurveyMonkey: 
  - Платформа для створення та управління опитуваннями
  - Пропонує аналітичні функції для оцінки результатів
  
- Qualtrics: 
  - Потужна платформа для створення опитувань
  - Використовується в наукових дослідженнях для збору та аналізу даних

#### 2. Веб-скрапінг (Web Crawling)
Ця техніка дозволяє витягувати дані з веб-сторінок для подальшого аналізу

- Beautiful Soup (Python): 
  - Бібліотека для парсингу HTML і XML документів, що дозволяє отримувати дані з веб-сторінок
  
- Scrapy: 
  - Фреймворк для збору даних з веб-сайтів
  - Ефективно організовує процес скрапінгу
  
- Octoparse: 
  - Інструмент для веб-скрапінгу без коду
  - Легко збирає дані з веб-сайтів за допомогою інтуїтивно зрозумілого інтерфейсу

#### 3. API (Application Programming Interface)
Використання API дозволяє отримувати дані з зовнішніх систем та сервісів

- Postman: 
  - Інструмент для тестування API, що дозволяє відправляти запити та отримувати дані
  
- Python Requests: 
  - Бібліотека для роботи з HTTP-запитами в Python
  - Дозволяє отримувати дані з API
  
- RapidAPI: 
  - Платформа, що надає доступ до тисяч API
  - Спрощує інтеграцію даних з різних джерел


### Обробка даних
На цьому етапі дані перевіряються, очищаються і трансформуються для подальшого аналізу. Це може включати видалення дублікатів, заповнення пропусків, нормалізацію даних та їх форматування. Якість даних є критично важливою на цьому етапі, оскільки неякісні дані можуть призвести до хибних висновків під час аналізу.

#### 1. Перевірка даних
- Валідація даних: використання правил та обмежень для перевірки коректності значень (наприклад, формат дати, діапазон чисел)
- Логічна перевірка: перевірка взаємозв’язків між різними полями (наприклад, дата народження не може бути пізніше дати реєстрації)

#### 2. Очищення даних
- Видалення дублікатів: виявлення і видалення повторюваних записів за допомогою алгоритмів (наприклад, методом обчислення унікальних значень)
- Заповнення пропусків: використання методів, таких як:
  - Середнє, медіана, мода для числових даних
  - Заповнення найближчим значенням для часових рядів
  - Інтерполяція для більш складних випадків

#### 3. Трансформація даних
- Нормалізація даних: зведення значень до одного масштабу без спотворення різниці в діапазонах (наприклад, перетворення значень у відсотки)
- Кодування категоріальних змінних: використання технік, таких як "one-hot encoding", для перетворення категоріальних змінних у числовий формат, щоб їх можна було використовувати в алгоритмах машинного навчання
- Форматування даних: зміна форматів даних (наприклад, дати в єдиний стандарт) для уникнення помилок під час обробки

### Зберігання даних
Після обробки дані зберігаються в базах даних або інших системах зберігання, таких як хмарні платформи. Важливо забезпечити належний рівень доступності та безпеки даних, щоб уникнути їх втрати або несанкціонованого доступу. Вибір формату зберігання (реляційна, NoSQL, файлові системи тощо) залежить від типу даних і вимог до їх використання.

#### 1. Формат зберігання
- *Реляційні бази даних*:
  - Підходять для структурованих даних, які мають чіткі зв’язки між таблицями
  - Переваги: транзакційна підтримка, потужні механізми запитів (SQL)
  - Приклади: PostgreSQL, MySQL, Oracle Database

- *NoSQL бази даних*:
  - Використовуються для неструктурованих або напівструктурованих даних
  - Переваги: гнучкість схеми, масштабованість
  - Типи NoSQL баз: 
    - Документні (MongoDB, CouchDB)
    - Ключ-значення (Redis, Amazon DynamoDB)
    - Графові (Neo4j, ArangoDB)
  
- *Файлові системи*:
  - Зберігання даних у форматі файлів на локальних або мережевих дисках
  - Підходять для великих обсягів даних, що не потребують складних запитів
  - Приклади: Amazon S3, Google Cloud Storage

#### 2. Хмарні платформи
- *Переваги хмарного зберігання*:
  - Масштабованість: можливість швидкого розширення ресурсів
  - Доступність: доступ до даних з будь-якого місця та в будь-який час
  - Резервне копіювання та відновлення: автоматизовані механізми для захисту даних
  
- *Популярні хмарні платформи*:
  - Amazon Web Services (AWS): сервіс S3 для об’єктного зберігання
  - Google Cloud Platform (GCP): Google Cloud Storage
  - Microsoft Azure: Azure Blob Storage

#### 3. Інструменти:
- *Системи управління базами даних (СУБД)*:
  - PostgreSQL: потужна реляційна СУБД з підтримкою розширень
  - MongoDB: популярна NoSQL база даних, що використовує документи
  - Cassandra: розподілена NoSQL база даних, яка забезпечує високу доступність та масштабованість

- *Хмарні сервіси*:
  - Amazon RDS: керований сервіс для реляційних баз даних
  - Firebase: платформа для зберігання даних у реальному часі

- *Інструменти резервного копіювання*:
  - Bacula: програмне забезпечення для резервного копіювання та відновлення
  - Veeam Backup: рішення для резервного копіювання віртуальних середовищ

### Аналіз даних
На цьому етапі дані аналізуються з метою отримання корисної інформації, виявлення закономірностей або підтримки прийняття рішень. Аналіз може здійснюватися різними методами, такими як статистичний аналіз, машинне навчання або візуалізація даних. Важливою складовою є інтерпретація результатів аналізу, що дозволяє зробити обґрунтовані висновки.

#### Підходи та інструменти
- *Статистичний аналіз*:
  - Використання статистичних методів для виявлення тенденцій та закономірностей.
  - Інструменти: R, Python (бібліотеки pandas, NumPy).
  
- *Машинне навчання*:
  - Застосування алгоритмів для навчання моделей на основі даних та прогнозування.
  - Інструменти: Scikit-learn, TensorFlow, Keras.

- *Візуалізація даних*:
  - Створення графіків і діаграм для наочності даних та висновків.
  - Інструменти: Tableau, Power BI, Matplotlib.

### Безпека даних
Забезпечення безпеки даних є критично важливим на всіх етапах їх життєвого циклу. Це включає фізичну безпеку (захист серверів і обладнання), а також кібербезпеку (шифрування, контроль доступу, моніторинг загроз). Важливо також мати політики та процедури для реагування на інциденти безпеки.

### Поширення даних
Після аналізу дані можуть бути надані різним користувачам або організаціям. Це може відбуватися через публікацію звітів, візуалізацій або через API для інтеграції з іншими системами. Важливо забезпечити, щоб дані були зрозумілі та доступні для споживачів, а також дотримуватися вимог щодо конфіденційності та захисту даних.

### Архівування та знищення даних
Коли дані більше не потрібні для активного використання, їх можна архівувати для зберігання на тривалий термін або безпечно знищити, якщо це необхідно. Архівування даних дозволяє зберегти їх для майбутнього використання, наприклад, для аудиту чи наукових досліджень. Процес знищення даних має відповідати законодавчим вимогам і внутрішнім політикам організації, щоб запобігти можливим витокам конфіденційної інформації.

#### Архівування даних:
- Архівування забезпечує зберігання даних на тривалий термін для потенційного подальшого використання, наприклад, для аудитів, аналізу тенденцій або наукових досліджень.

#### Безпечне знищення даних:
- Використання методів знищення, таких як деструкція дисків, перезапис даних (data wiping) або знищення за стандартами, щоб гарантувати, що дані не можуть бути відновлені.

Управління відкритими даними є одним із ключових завдань в роботі з ними, яке можна реалізувати у різні способи. У цьому розділі ми розглянемо основні підходи та моделі, що можуть бути застосовані для розробки систем управління відкритими даними.

### Методи збору даних

**[Веб-скрапінг (англ. Web Scraping)](https://apix-drive.com/ua/blog/ecommerce/web-scraping)** - це модель автоматичного отримання даних із веб-сторінок відповідно до заданих параметрів. Даний спосіб полягає в тому, щоб програмному витягу інформації з веб-сторінок, що знаходяться в публічному доступі, і перетворенні її у структуровані дані з подальшою можливістю аналізу та використання для різних цілей. Веб-скрапінг дозволяє автоматизувати процес збору даних з Інтернету і зазвичай використовується для таких задач, як аналіз ринку, моніторинг цін, збір новин або побудова баз даних.

Серед плюсів даного підходу можна виділити:

- Доступність даних: Інформацію можна отримувати з різних джерел, навіть якщо ця інформація не надається у вигляді відкритих даних.

- Широкий спектр даних: Веб-скрапінг здатний збирати різні за типом дані, як-от текст, мультимедіа, ціни, оголошення, новини тощо. Завдяки цьому даний метод є доцільним для використання з метою збору різноманітних видів інформації.

- Автоматизація: Метод веб-скрапінгу дозволяє економити час і ресурси завдяки перевірці веб-сайтів скриптом.

Серед мінусів даного підходу варто зважати на:

- Юридичні обмеження: Веб-скрапінг може порушувати авторські права, адже деякі власники веб-сторінок встановлюють обмеження на використання даних, що представлені на сторінці. Ігнорування подібних нюансів може призвести до наслідків з точки зору закону.

- Вимоги до ресурсів і обладнання: Великі обсяги даних або інтенсивність роботи скрипту може вимагати високої пропускної здатності мережі та неабияких обчислювальних ресурсів, через що можливе зростання витрат на обладнання і хостинг.

**Краудсорсинг (англ. Crowdsourcing)** - це підхід у галузі відкритих даних, який передбачає залучення великої кількості людей, або волонтерів, які за власною згодою збирають масиви даних для проекту, оновлюють дані та підтримують якість самих даних у системі управління відкритих даних.

Серед плюсів даного підходу можна виділити:

- Масштабність: Краудсорсинг дозволяє залучити велику кількість учасників, що дозволяє збирати та оновлювати великі обсяги даних.

- Різноманітність даних: Учасники можуть мати різні спектри інтересів, що дозволяє розширювати розмах даних та їх різноманітність.

- Гнучкість: Завдяки гнучкості, краудсорсинг може бути використаний для різних завдань, включаючи створення, валідацію та оновлення даних.

- Ефективність витрат ресурсів: Краудсорсинг може бути більш ефективним і економічним способом збору та обробки даних чим інші традиційні способи.

Серед мінусів даного підходу варто зважати на:

- Якість і точність даних: Учасники можуть не бути спеціалістами в конкретній області, що може призвести до низької якості та неточності зібраних даних. Це вимагає окремої уваги до валідації та перевірки інформації.

- Контроль і координація: Керування великою кількістю учасників може бути складним завданням. Для забезпечення стабільної роботи необхідним є ефективне управління та нагляд, що вимагає певних ресурсів.

- Часові рамки і затримки: Реалізація проекту, що використовує краудсорсинг, може займати більше часу через необхідність обробки та перевірки великої кількості даних.

  Прикладами використання методу краудсорсингу є проєкти, де громадськість допомагає розпізнавати текст на зображеннях (Optical Character Recognition), маркувати географічні об'єкти на мапах, аналізувати дані для наукових досліджень, та багато інших. У контексті управління відкритими даними, краудсорсинг може бути корисним для поповнення та підтримки наборів даних, щоб забезпечити актуальність та точність інформації.

**API** - набір програмного коду, що дозволяє взаємодію між програмами, запит та обмін даними і спрощує комунікацію між різними програмними платформами. [API](https://ru.wikipedia.org/wiki/API) бувають публічними, партнерськими, приватними та складними.

Серед плюсів даного підходу можна виділити:

- Економію: Робота із готовим кодом заощаджує час та кошти, що могли бути використані на розробку з нуля.

- Передбачуваність: У кожній новій програмі інтерфейс працюватиме вже знайомим зрозумілим чином.

До мінусів можна віднести: 

- Поверхневість розуміння принципів роботи: Використання розробником чужого API може мати підводні камені у вигляді нерозуміння принципів роботи вихідного коду.

- Обмеженість: Готовий API не вдасться вдосконалити новим функціоналом.

**Database extraction або витяг з бази даних** - це процес отримання даних з бази даних для подальшого використання. Він передбачає використання мови запитів, такої як SQL (мова структурованих запитів), для безпосередньої взаємодії з базою даних і вилучення необхідних даних. Витягнуті дані можуть бути використані з метою аналізу, звітності або введення в інші системи. Процес вилучення можна налаштувати для отримання конкретних даних, які відповідають певним критеріям, що робить його гнучким і потужним інструментом для управління даними.

Серед особливостей цього методу варто відзначити:
- Доступ до структурованих даних.

- Гнучкість і потужність.

- Ефективний пошук даних.

- Зручність маніпулювання даними.

- Зручну інтеграцію з іншими технологіями.

### Методи зберігання даних

**База даних (англ. Database)** - це модель зберігання даних у вигляді структурованих колекцій даних, яка зберігається на носіях даних та доступна через сервер системи, може використовуватися для ефективного пошуку, оновлення та аналізу. Також існують різні види баз даних, тому треба звертати фокусуватися на їх особливостях:

*Реляційні бази даних* — це тип системи керування базами даних (RDBMS), яка використовується для ефективного та структурованого зберігання та організації великих обсягів інформації.

Реляційна БД складається з однієї або кількох таблиць, які містять інформацію, пов’язану одна з одною. Кожна таблиця складається з рядків і стовпців, де кожен рядок представляє запис, а кожен стовпець представляє атрибут або поле інформації.

Основною метою реляційних баз даних є забезпечення структурованої та організованої форми зберігання даних, яка дозволяє легко шукати та оновлювати інформацію. Крім того, вони також дозволяють ефективно й точно виконувати складні запити, що включають кілька таблиць.

Однією з головних переваг реляційних баз даних є їх здатність забезпечувати цілісність даних і узгодженість інформації. Визначивши зв’язки та обмеження між таблицями, можна переконатися, що дані, які зберігаються в базі даних, є точними та послідовними. Це має особливу важливість в критичних бізнес-додатках, де обробляються великі обсяги інформації.

Ще однією важливою перевагою реляційних баз даних є їхня здатність масштабуватись і рости разом із бізнесом. Замість того, щоб переходити на нову платформу або систему керування базами даних, коли потрібна додаткова ємність, реляційні бази даних можна розширювати та коригувати в міру зростання бізнесу. 

*NoSQL* — база даних, яка забезпечує механізм зберігання та видобування даних відмінний від підходу таблиць-відношень в реляційних базах даних.

Мотиви цього підходу включають:
- Простоту дизайну схеми БД

- Тонкий контроль над доступністю.
  
- Значно спрощене горизонтальне масштабування на кластери машин (що є проблемою для реляційних баз даних)

Структури даних, що використовуються в NoSQL (такі як ключ-значення, сховище з широким стовпчиком, граф, документ) є відмінними від тих, що використовуються за замовчуванням в реляційних базах, що робить тим самим деякі операції над даними значно швидшими на NoSQL.

Серед особливостей використання NoSQL варто зазначити наступні:
- Багато NoSQL сховищ нехтують узгодженістю даних (у сенсі [теореми CAP](https://uk.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D0%B5%D0%BC%D0%B0_CAP)) на противагу доступності, толерантності до партиціонування, та, звісно, швидкості. Бар'єрами прийняття парадигми NoSQL сховищ є використання низькорівневої мови запитів (замість добре розвиненого та стандартизованого SQL), брак стандартизованих інтерфейсів і значні інвестиції уже в існуючі реляційні бази.
  
- Більшість NoSQL баз даних пропонують концепцію випадкового узгодження даних, в якому зміни в базі продубльовано на всі вузли «випадковим чином» (зазвичай така дія займає мілісекунди), що запити даних можуть не повернути оновлені дані моментально, або ж прочитані дані будуть не точними — давно знана проблема читання станів. На додаток, деякі NoSQL системи можуть демонструвати втрачені записи та інші форми втрати даних. На щастя, деякі NoSQL забезпечують принцип [WAL-журналювання](https://uk.wikipedia.org/wiki/WAL-%D0%B6%D1%83%D1%80%D0%BD%D0%B0%D0%BB%D1%8E%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F) для уникнення втрати даних.

*Гібридна база даних* - це система керування базами даних (СКБД), яка об'єднує в собі реляційні та нереляційні (NoSQL) підходи до зберігання даних. Вона надає гнучкість у використанні структурованих, напівструктурованих та невідомих форматів даних. Гібридні бази даних забезпечують високу продуктивність та масштабованість, що дозволяє їм ефективно обробляти великі обсяги даних у реальному часі. Вони є ідеальним рішенням для компаній, які потребують зберігати та обробляти різноманітні дані від різних джерел.

Серед переваг використання Гібридних БД варто зазначити:

- Гнучкість: Можливість працювати з різноманітними типами даних.
  
- Масштабованість: Здатність розширювати обсяги даних та обсяги транзакцій для відповіді на зростаючі потреби бізнесу.
  
- Високу доступність: Забезпечення доступності до даних за будь-яких обставин.
  
- Ефективність: Оптимізація продуктивності та швидкості доступу до даних.

Серед недоліків використання цього методу потрібно зважати на:

- Відносну складність управління: Завдяки комбінації різних моделей даних, гібридні бази даних можуть бути складними у розробці та управлінні.

- Витрати на обслуговування: Підтримка гібридної інфраструктури може призвести до збільшення витрат на обслуговування та підтримку.

*Системи зберігання в хмарі (Cloud Storage Systems)* - це спеціальні сервіси, які надають можливість зберігати дані в розподіленому, віддаленому середовищі через Інтернет. Вони дозволяють користувачам зберігати, керувати та отримувати доступ до своїх файлів і даних з будь-якого пристрою, підключеного до мережі Інтернет.

Основні переваги Систем хмарного зберігання включають:

- Масштабованість: Системи зберігання в хмарі зазвичай мають велику потужність і можуть масштабуватися в залежності від потреб користувача. Це дозволяє зберігати великі обсяги даних та забезпечувати їх доступність.

- Доступність: Дані, збережені в хмарі, доступні з будь-якого місця з доступом до Інтернету. Це робить їх ідеальним варіантом для забезпечення доступу до даних з різних пристроїв та місць роботи.

- Надійність: Багато Cloud Storage Systems забезпечують резервне копіювання даних та механізми відновлення, що робить їх надійними для зберігання важливої інформації та даних.

- Безпека: Системи зберігання в хмарі часто надають різні заходи безпеки, такі як шифрування даних, двофакторна аутентифікація та контроль доступу, щоб забезпечити захист конфіденційної інформації.

- Еластичність вартості: Користувачі сплачують лише за фактичне використання обсягу даних, що дозволяє ефективно керувати витратами на зберігання.

Однак, існують деякі недоліки систем зберігання в хмарі:

- Залежність від Інтернет-з'єднання: Для доступу до даних, збережених в хмарі, потрібне постійне Інтернет-з'єднання. Відсутність зв'язку може призвести до недоступності даних.

- Обмеження управління: Не всі хмарні системи надають розширені можливості управління даними, такі як резервне копіювання, відновлення та архівування, що може обмежити можливості користувача в управлінні своїми даними.

- Несумісність з правовими вимогами: Використання хмарних систем зберігання даних може суперечити деяким правовим вимогам, таким як вимоги щодо зберігання даних в конкретних країнах або вимоги до захисту конфіденційної інформації.

- Обмежені можливості налаштування: У деяких випадках хмарні системи зберігання даних можуть мати обмежені можливості налаштування або адаптації під конкретні потреби користувача.

Не зважаючи на ці недоліки, хмарні системи зберігання даних стали невід'ємною частиною сучасного бізнесу та інформаційних технологій, надаючи ефективність, гнучкість та безпеку в зберіганні та управлінні даними.

### Аналіз даних та їх обробка

**[TensorFlow](https://uk.wikipedia.org/wiki/TensorFlow)** — відкрита програмна бібліотека для машинного навчання цілій низці задач, розроблена компанією Google для задоволення її потреб у системах, здатних будувати та тренувати нейронні мережі для виявляння та розшифровування образів та кореляцій, аналогічно до навчання й розуміння, які застосовують люди.

TensorFlow застосовується як для досліджень, так і для розробки власних продуктів Google. Основний API для роботи з бібліотекою реалізований для Python, проте також існують реалізації для R, C#, C, Haskell, Java, Go, JavaScript та Swift.

Також на основі TensorFlow базується платформа машинного навчання [TFX](https://www.tensorflow.org/tfx/guide). Він надає структуру конфігурації та спільні бібліотеки для інтеграції загальних компонентів, необхідних для визначення, запуску та моніторингу вашої системи машинного навчання.

[Бібліотеки TFX включають:](https://www.tensorflow.org/tfx/guide)
- TensorFlow Data Validation (TFDV) – це бібліотека для аналізу та перевірки даних машинного навчання. Він розроблений з високою масштабованістю і добре працює з TensorFlow та TFX.

- TensorFlow Transform (TFT) – це бібліотека для попередньої обробки даних за допомогою TensorFlow.

- Аналіз моделей TensorFlow (TFMA) – це бібліотека для оцінки моделей TensorFlow. Це дозволяє користувачам оцінювати свої моделі на великих обсягах даних розподіленим чином.

- Метадані TensorFlow (TFMD) надають стандартні уявлення метаданих, які корисні для навчання моделей машинного навчання за допомогою TensorFlow. Метадані можуть створюватися вручну або автоматично під час аналізу вхідних даних та можуть використовуватися для перевірки, дослідження та перетворення даних.

- ML Metadata (MLMD) - це бібліотека для запису та вилучення метаданих, пов'язаних з робочими процесами розробників машинного навчання та фахівців за даними. Найчастіше метадані використовують уявлення TFMD.

**Машинне навчання (англ. Machine learning)** - це модель автоматичного аналізу та обробки даних завдяки використанню існуючих математичних моделей. Машинне навчання дозволяє знаходити тренди у даних та створювати прогнози на основі отриманих даних, а також виявлення аномалій і покращення рішень які вже використовуються системою.

Машинне навчання має дані особливості:

- Асоціативні правила - метод машинного навчання дозволяє виявляти закономірності та взаємозв'язки між даними на основі правил.

- Класифікація - метод машинного навчання який використовується для призначення кожного об'єкту до одного з попередньо визначених класів або категорій на основі аналізу даного об'єкту.

- Кластеризація - метод, який розбиває вибірки даних на підмножини, які називаються кластерами, так, щоб кожен кластер складавсі зі схожих об'єктів, а об'єкти різних кластерів істотно відрізнялися.

- Регресія - використовується у випадках коли потрібно за заданим набором ознак спрогнозувати майбутню змінну. Завдання регресії передбачення місця на числовій прямій.

- Визначення тренду - на основі даних формує загальне передбачення зміни змінних.

- Виявлення аномалій - машинне навчання дозволяє виявляти та визначати аномалії у структурі даних та у її вибірці.

Для аналізу даних людиною, зазвичай потрібна візуалізація тих самих даних. Тому для цього існує багато методів візуалізації даних, які допомагають представити інформацію у вигляді графічних зображень, щоб спростити розуміння та аналіз даних. 

**Ось деякі з найпоширеніших методів візуалізації даних:**

- Графіки та діаграми:

  - Лінійні графіки: Використовуються для відображення зміни значень одного або кількох параметрів з часом.

  - Стовпчикові графіки: Допомагають порівнювати значення різних категорій або об'єктів.

  - Кругові діаграми: Використовуються для відображення часток у відсотках від загальної суми.

- Графіки розсіювання (англ. Scatter Plots): Використовуються для візуалізації відношень між двома числовими параметрами. Дозволяють виявляти кореляції та викиди даних.

- Теплові карти (англ. Heatmaps): Показують інтенсивність значень в матриці даних за допомогою кольорів. Це корисний метод для виявлення шаблонів та аномалій у великих наборах даних.

- Дерева прийняття рішень (англ. Decision Trees): Використовуються для відображення процесу прийняття рішень у вигляді дерева з рішеннями та розділеннями, що базуються на значеннях атрибутів.

- Картографічні візуалізації: Використовуються для представлення географічних даних на картах. До прикладів належать карти розташування точок і графіки з використанням геоданих.

- 3D-візуалізація: Використовується для представлення тривимірних даних у тривимірному просторі для аналізу об'єктів з трьох вимірів.

- Анімація: Використовується для відстеження змін у даних з часом та надає можливість переглядати еволюцію даних.

- Графіки мереж (англ. Network Graphs): Використовуються для візуалізації складних мереж, таких як соціальні мережі, графи залежностей тощо.

- Графіки дерев (англ. Tree Diagrams): Допомагають візуалізувати ієрархічну структуру даних, таку як організаційні структури.\

### Забезпечення конфіденційності та доступу

**Ролева модель доступу (англ. Role-Based Access Control, RBAC)** - це система контролю доступу, яка базується на призначенні користувачам ролей та наданні прав доступу до ресурсів на основі цих ролей. В контексті системи управління відкритими даними, RBAC може бути важливим компонентом для забезпечення безпеки та керування доступом до різних функціональних можливостей та даних системи.

Основні компоненти ролевої моделі доступу включають:

- Користувачі (англ. Users): Користувачі системи прив'язуються до однієї чи декількох ролей. Кожен користувач має можливість виконувати дії, які дозволені його або її ролю.

- Ролі (англ. Roles): Ролі - це набори прав доступу, які групують користувачів зі схожими функціональними обов'язками або рівнями доступу. Прикладами ролей можуть бути "адміністратор", "модератор", "гість" тощо.

- Права доступу (англ. Permissions): Права доступу визначають, які дії користувачів дозволено виконувати щодо конкретних ресурсів (наприклад, перегляд, редагування, видалення даних). Кожна роль має набір прав доступу.

- Сесії (англ. Sessions): Сесії відстежують активність користувачів у системі та контролюють їх автентифікацію та авторизацію.

- Управління ролями англ. (англ. Role Management): Адміністратор системи відповідає за призначення ролей користувачам, зміну наборів прав доступу та визначення, які користувачі мають доступ до конкретних ресурсів.

- Логування та аудит (англ. Logging and Auditing): Система може вести журнали подій, щоб відстежувати виконання користувачами певних дій та змін даних, що допомагає виявляти можливі аномалії та порушення безпеки.

- Внутрішні інтерфейси та API (англ. Internal Interfaces and APIs): Для реалізації RBAC можуть бути використані спеціальні програмні інтерфейси та API, які дозволяють розробникам легко ідентифікувати ролі користувачів та правила доступу до ресурсів.

Ролева модель доступу спрощує керування безпекою і доступом до даних, дозволяючи адміністраторам системи ефективно контролювати, які користувачі мають доступ до певних ресурсів і операцій, що вони можуть виконувати. Вона також допомагає уникнути надмірної складності в управлінні окремими правами для кожного користувача, спрощуючи процес адміністрування системи.

## Порівняльна характеристика існуючих засобів вирішення завдання

CKAN: CKAN — це одна з найпопулярніших платформ для управління відкритими даними. Це програмне забезпечення з відкритим кодом, яке дозволяє урядам та організаціям публікувати, каталогізувати та управляти даними. Платформа підтримує розширення через систему плагінів і надає API для інтеграції з іншими системами. Вона також має інструменти для візуалізації даних, хоча для налаштування та обслуговування потрібні технічні знання.

Socrata Open Data: Socrata — це платформа, орієнтована на державні установи, що спеціалізується на управлінні та публікації відкритих даних. Вона пропонує зручний інтерфейс, можливість створення аналітичних порталів та інтеграцію з іншими державними системами через API. Платформа забезпечує високу продуктивність для великих обсягів даних та аналітичні інструменти для детального аналізу.

OpenDataSoft: OpenDataSoft пропонує всебічну платформу для управління, публікації та візуалізації відкритих даних. Вона підтримує інтеграцію з іншими платформами через API та забезпечує зручний інтерфейс для користувачів без глибоких технічних знань. Платформа також пропонує готові рішення для аналізу та роботи з даними, роблячи дані доступними для широкого кола користувачів завдяки зручним інструментам візуалізації.

Dataverse: Dataverse — це платформа для зберігання, управління та публікації наукових даних, зокрема для університетських та дослідницьких інституцій. Вона підтримує розширені можливості для метаданих, контролю доступу та підтримки версійності даних. Dataverse орієнтована на академічне використання, але може застосовуватись і для загального управління відкритими даними.

OpenGov: OpenGov — це державна платформа, яка надає рішення для управління відкритими даними, аналітики та фінансового управління. Вона відома своїми потужними інструментами для створення звітів та бюджетних аналізів, що робить її корисною для муніципальних органів влади. Платформа забезпечує високу інтеграцію з фінансовими та адміністративними системами.

Критерії:

🟢 - функція реалізована
🟠 - функція реалізована, проте має недоліки
❌ - функція не реалізована


| Категорія       | Критерій                            | CKAN      | Socrata Open Data | OpenDataSoft         | Dataverse | OpenGov                     |
|-----------------|-------------------------------------|-----------------------------|-----------|-------------------|----------------------|-----------|
| **Functionality**| Створення, редагування датасетів   | 🟢                | 🟢                    | 🟢        | 🟢                         |
|                 | Підтримка багатомовності            | ❌        | 🟢                | 🟢                    | ❌        | 🟢                         |
|                 | Вбудовані аналітичні інструменти    | 🟠        | 🟢                | 🟢                    | ❌        | 🟢                         |
|                 | Пошук і фільтрація за категоріями   | 🟢        | 🟢                | 🟢                    | 🟢        | 🟢                         |
|                 | Інтеграція з API                    | 🟢        | 🟢                | 🟢                    | 🟠        | 🟢                         |
| **Usability**   | Експорт даних у різних форматах     | 🟢        | 🟢                | 🟢                    | 🟢        | 🟢                         |
|                 | Наявність навчальних матеріалів     | 🟠        | 🟢                | 🟢                    | 🟢        | 🟠                         |
|                 | Інтуїтивний інтерфейс (UI/UX)       | 🟠        | 🟢                | 🟢                    | 🟢        | 🟢                         |
| **Reliability** | Ліцензії та захист авторських прав  | 🟢        | 🟢                | ❌                    | 🟢        | 🟢                         |
|                 | Перевірка даних і валідація         | 🟠        | 🟢                | 🟠                    | 🟠        | 🟠                         |
| **Performance** | Оцінка швидкості завантаження       | 🟢        | 🟢                | 🟢                    | 🟢        | 🟢                         |
|                 | Продуктивність при навантаженні     | 🟠 85     | 🟠 80             | 🟢 90                 | ❌ 78     | 🟢 88                      |
| **Supportability**| Технічна підтримка та документація| 🟢        | 🟢                | 🟠                    | 🟢        | 🟢                         |
|                 | Актуальність оновлень               | 🟠        | 🟠                | 🟠                    | 🟢        | 🟠                         |


## Висновки
Аналіз сучасних платформ для управління відкритими даними, таких як CKAN, Socrata, OpenDataSoft, Dataverse та OpenGov, демонструє різноманітність підходів до публікації, каталогізації та управління даними. Кожна з цих платформ має свої переваги та недоліки, які можуть впливати на вибір конкретного рішення.

1. **Доцільність розробки нової або модифікації існуючої інформаційної системи**:
- В умовах постійного зростання обсягу даних та вимог до їх відкритості, розробка нової інформаційної системи або модернізація існуючої є необхідною для забезпечення ефективного управління даними. Системи, які не відповідають сучасним стандартам, можуть обмежувати доступність та використання даних, а також ускладнювати процеси аналізу та візуалізації.

- Вибір платформи, що найкраще відповідає потребам організації, може істотно підвищити продуктивність, доступність даних і покращити взаємодію з користувачами.


2. **Необхідність інтеграції з системами третіх сторін**:
- Інтеграція з існуючими системами та сервісами, такими як CRM, аналітичні платформи та фінансові системи, дозволяє розширити функціональність нової або модернізованої системи, поліпшити обмін даними та забезпечити більш гнучке управління інформацією.

- API, які пропонують більшість платформ, можуть значно спростити процес інтеграції, дозволяючи з'єднувати різні системи без потреби у складних налаштуваннях.

Таким чином, в умовах динамічного розвитку технологій і зростання вимог до відкритих даних, розробка нових інформаційних систем або модифікація існуючих є важливими для забезпечення високої ефективності, гнучкості та безпеки даних. Проведення аналізу предметної області необхідне для знаходження правильних підходів побудови системи управління відкритими даними та визначення необхідних функцій, які треба реалізувати у даній системі.

## Посилання
1. [Відкриті дані](https://leadscanner.com.ua/articles/open-data)
2. [SQL (Structured Query Language)](https://www.bing.com/ck/a?!&&p=3b144276e772932ae8a56f1d76ff964d64b673a16cedd49f7be90965cb40abd2JmltdHM9MTczMDI0NjQwMA&ptn=3&ver=2&hsh=4&fclid=362a8653-e5e5-6d7c-1f3f-948ae44f6cbd&psq=SQL+(Structured+Query+Language)&u=a1aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvU1FM&ntb=1).
3. [База даних (англ. Database)](https://apeps.kpi.ua/shco-take-basa-danykh)
4. [СУБД (Система управління базами даних](https://apeps.kpi.ua/shco-take-basa-danykh)
5. [РБД (Розподілені бази даних)](https://apeps.kpi.ua/shco-take-basa-danykh)
6. [Ролева модель доступу (англ. Role-Based Access Control, RBAC)](https://uk.wikipedia.org/wiki/%D0%9A%D0%B5%D1%80%D1%83%D0%B2%D0%B0%D0%BD%D0%BD%D1%8F_%D0%B4%D0%BE%D1%81%D1%82%D1%83%D0%BF%D0%BE%D0%BC_%D0%BD%D0%B0_%D0%BE%D1%81%D0%BD%D0%BE%D0%B2%D1%96_%D1%80%D0%BE%D0%BB%D0%B5%D0%B9)
7. [Прикладний програмний інтерфейс (англ. Application Programming Interface, API)](https://ua.nesrakonk.ru/application-programming-interface/)
8. [Нереляційна база даних (англ. Non Relation Data Base)](https://www.google.com/search?q=non+relational+database&oq=no+relation&aqs=chrome.1.69i57j0i10i512j0i512l2j0i10i512l2j0i512l3j0i10i512.5519j0j4&sourceid=chrome&ie=UTF-8)
9. [Система управління базами даних](https://www.ibm.com/docs/en/zos-basic-skills?topic=zos-what-is-database-management-system)
10. [Краудсорсинг (англ. Crowdsourcing)](https://novarobota.ua/ua/articles-jobseeker/kraudsorsing-chto-eto-takoe-i-kak-on-rabotaet-v-biznese-413)
11. [Веб-скрапінг (англ. Web Scraping)](https://apix-drive.com/ua/blog/ecommerce/web-scraping)
12. [API (Application Programming Interface)](https://www.bing.com/ck/a?!&&p=27462302d85583ebc895bf214994ea30013c1887b98243806e95abe46d9a28d5JmltdHM9MTczMDI0NjQwMA&ptn=3&ver=2&hsh=4&fclid=362a8653-e5e5-6d7c-1f3f-948ae44f6cbd&psq=api&u=a1aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvQVBJ&ntb=1)
13. [Хмарні технології](https://edin.ua/shho-take-xmarni-texnologi%D1%97-i-navishho-voni-potribni/)
14. [Реляційна база даних](https://ua5.org/database/189-reljacjjna-baza-danikh.html)
17. [Нереляційна база даних](https://www.google.com/search?q=non+relational+database&oq=no+relation&aqs=chrome.1.69i57j0i10i512j0i512l2j0i10i512l2j0i512l3j0i10i512.5519j0j4&sourceid=chrome&ie=UTF-8)
18. [CKAN](https://ckan.org/)
19. [DATA.GOV](https://data.gov/)
20. [OpenDataSoft](https://www.opendatasoft.com)
21. [Socrata](https://dev.socrata.com/)
